name: "abbreviation_generation_POC"

data:
    train: "data/"
    dev:  "data/"
    test: "data/"
    dataset_type: "plain"
    sample_train_subset: -1
    sample_dev_subset: -1
    src:
        lang: "src"
        max_length: 100
        min_length: 1
        lowercase: False
        normalize: False
        level: "word"
        voc_limit: 400
        voc_min_freq: 1
        voc_file: "example/vocab.txt"
        tokenizer_type: "sentencepiece"
        tokenizer_cfg:
            #model_file:
            #alpha: 0.0
            #nbest_size: 
            character_coverage: 1.0
            model_type: "unigram"
            pretokenizer: "none"
    tgr:
        lang: "tgt"
        max_length: 100
        min_length: 1
        lowercase: False
        normalize: False
        level: "word"
        voc_limit: 400
        voc_min_freq: 1
        voc_file: "example/vocab.txt"
        tokenizer_type: "sentencepiece"
        tokenizer_cfg:
            #model_file:
            #alpha: 0.0
            #nbest_size: 
            character_coverage: 1.0
            model_type: "unigram"
            pretokenizer: "none"
    testing:
        n_best: 1
        beam_size: 5
        beam_alpha: 1.0
        batch_size: 5
        batch_type: "sentence"
        eval_metrics: ["token_accuracy"]
        max_output_length: 100
        min_output_length: 1
        return_prob: "none"
        generate_unk: False
        no_repeat_ngram_size: -1
        repetition_penalty: -1
    
    training:
        #load_model: N/A currently
        reset_best_ckpt: False
        reset_scheduler: False
        reset_optimizer: False
        reset_iter_state: False
        random_seed: 42
        optimizer: "adam"
        adam_betas: [0.9,0.999]
        learning_rate: 0.005
        learning_rate_min: 0.0001
        clip_grad_val: 1.0
        weight_decay: 0.
        loss: "crossentropy"
        label_smoothing: 0.0
        batch_size: 5
        batch_type: "sentence"
        batch_multiplier: 1
        normalization: "batch"
        scheduling: "plateau"
        patience: 5
        decrease_factor: 0.5
        epochs: 1
        updates: 100
        validation_freq: 5
        logging_freq: 5
        early_stopping_metric: "loss"
        model_dir: "poc"
        overwrite: False
        shuffle: True
        use_cuda: False
        print_valid_sents: [0,1,2]
        keep_best_chpts: 3
    
    model:
        initializer: "xaviar_uniform"
        init_weight: 0.01
        init_gain: 1.0
        bias_initializer: "zeros"
        embed_initializer: "normal"
        embed_init_weight: 0.1
        embed_init_gain: 1.0
        init_rnn_orthogonal: False
        lstm_forget_gate: 1/
        tied_embeddings: False
        tied_softmax: False
        encoder:
            type: "recurrent"
            rnn_type: "lstm"
            embeddings:
                embedding_dim: 16